{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts Distributor SKU classifier, part 1: Build the model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Electronic parts distributors like Digi-Key, Mouser etc assign their own product IDs (known as a SKU, or \"stock keeping unit\") to every product they sell, which is different from the \"part number\" that manufacturers assign to the products they make.\n",
    "\n",
    "For example, `SN74LVC541APWR` is a part number identifying a particular IC made by Texas Instruments. Digi-Key's assigned SKU for it is `296-8521-1-ND`. Mouser calls it `595-SN74LVC541APWR`.\n",
    "\n",
    "Once you look at a few examples, you'll notice simple patterns that allow you to (mostly) identify the source of each part number/SKU. If you wanted a computer to do that for you, regular expressions would work. _But that wouldn't be fun, would it?_\n",
    "\n",
    "This turns out to be a great toy problem to try some machine learning algorithms on. What we want to do is use a whole lot of labeled data (where we already know the answers from some other data source) to build a model that we can then ask to categorize part numbers/SKUs that it hasn't seen before.\n",
    "\n",
    "~~~\n",
    "Me: Hey computer, what's \"595-SN74LVC541APWR\"?\n",
    "Computer: That looks like a Mouser SKU.\n",
    "Me: Ok, how about \"296-8521-1-ND\"?\n",
    "Computer: Pretty sure it's a Digi-Key SKU.\n",
    "Me: And what about \"the AI is a lie\"?\n",
    "Computer: ...*&$*&^#$....\n",
    "~~~\n",
    "\n",
    "Since we'll be classifying sequences of characters, something like an [LSTM recurrent neural network](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) should do the trick.\n",
    "\n",
    "We'll be using a fairly typical machine learning environment: Python, pandas, numpy, Keras and TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "Let's start with a simple labeled dataset with 2 columns:\n",
    "- `partnum` is the part number/SKU string that we'll teach the model to classify\n",
    "- `class` is the known classification. It has 3 possible values:\n",
    "  - `0` is a manufacturer's part number\n",
    "  - `1` is a Mouser SKU\n",
    "  - `2` is a Digi-Key SKU\n",
    "\n",
    "Here are the first few rows of our source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partnum</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20658</th>\n",
       "      <td>478-5892-1-ND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19369</th>\n",
       "      <td>81-GRM21BR61E106KA3L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>ISL83485IBZ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>445-6947-6-ND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>1N4148WL2-TP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17903</th>\n",
       "      <td>GRM1555C1H201JA01D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19493</th>\n",
       "      <td>497-5923-1-ND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>MCP2542FDT-E/MFTR-ND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8294</th>\n",
       "      <td>RMCF0805JT200R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15136</th>\n",
       "      <td>296-28379-6-ND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    partnum  class\n",
       "20658         478-5892-1-ND      2\n",
       "19369  81-GRM21BR61E106KA3L      1\n",
       "2279            ISL83485IBZ      0\n",
       "4304          445-6947-6-ND      2\n",
       "2395           1N4148WL2-TP      0\n",
       "17903    GRM1555C1H201JA01D      0\n",
       "19493         497-5923-1-ND      2\n",
       "11986  MCP2542FDT-E/MFTR-ND      2\n",
       "8294         RMCF0805JT200R      0\n",
       "15136        296-28379-6-ND      2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('data/mpn_mouser_digikey.csv')\n",
    "class_names = ['MPN', 'Mouser SKU', 'Digi-Key SKU']\n",
    "df_raw.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be good to know how many examples of each class we have, to make sure we don't run into issues with [unbalanced training sets](https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set)\n",
    "\n",
    "Let's plot how many samples of manufacturer part numbers, Mouser SKUs and Digi-Key SKUs we have in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f919c6b2eb8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAELCAYAAAA/cjqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzHLMIWBmlmP/H7m3/w3jTEdKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f919e3c6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw.groupby('class').count().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a lot more samples of Digi-Key SKUs than others. Let's drop some data to equalize the number of samples in each class, and reshuffle the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4711"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit_rows_per_class = int(df_raw.groupby('class').count().min())\n",
    "limit_rows_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(list(df_raw[df_raw['class'] == c][:limit_rows_per_class] for c in df_raw['class'].unique()))\n",
    "df = df.sample(frac=1, random_state=20181203)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To [properly train the model and evaluate results](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6), we'll separate our data into 2 sets:\n",
    "- train - these are the rows that the model will be learning from. (80% of the data)\n",
    "- validate - use this data to evaluate the accuracy of the model. This data will NOT be used for actual training. (20% of the data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partnum</th>\n",
       "      <th>class</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>MPMT-10K/10KDKR-ND</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>556-ATMEGA328PB-MNR</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>652-CRA2512FZR100ELF</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>296-35502-1-ND</td>\n",
       "      <td>2</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>649-67997-106HLF</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    partnum  class dataset\n",
       "7218     MPMT-10K/10KDKR-ND      2   train\n",
       "18646   556-ATMEGA328PB-MNR      1   train\n",
       "4440   652-CRA2512FZR100ELF      1   train\n",
       "3437         296-35502-1-ND      2     val\n",
       "24360      649-67997-106HLF      1     val"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column, randomly assign each row to a dataset\n",
    "np.random.seed(20181203)\n",
    "df['dataset'] = np.random.choice(['train', 'val'], size=len(df), replace=True, p=[0.80, 0.20])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the inputs\n",
    "\n",
    "The Keras LSTM layer operates on dense vectors (arrays of floats). To turn our part number strings into sequences of vectors, we'll take two steps: turn the strings into sequences of integers using a dictionary to map every character to a number, then use [Keras's \"embedding\" layer](https://keras.io/layers/embeddings/) to turn those into vectors. We also need to remember to terminate every sequence with a special code (we'll use a zero) to tell the model when the input stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the dictionary - map every unique character to an integer\n",
    "unique_chars = set()\n",
    "for s in df['partnum'].values:\n",
    "    unique_chars |= set(c for c in s)\n",
    "partnum_dict = {c: i+1 for i, c in enumerate(unique_chars)}\n",
    "\n",
    "df['x'] = list(df['partnum'].map(lambda s: list(partnum_dict[c] for c in s)))\n",
    "maxlen = max(len(pn) for pn in df['partnum'].values)\n",
    "df['x'] = list(list(l) for l in sequence.pad_sequences(df['x'], maxlen=maxlen+1, padding='post'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a snippet of that dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Z', 1),\n",
       " ('G', 2),\n",
       " (' ', 4),\n",
       " ('.', 5),\n",
       " ('_', 6),\n",
       " ('A', 7),\n",
       " ('K', 8),\n",
       " ('-', 9),\n",
       " ('5', 10),\n",
       " ('8', 12)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(partnum_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tell our model which class a particular string belongs to, we'll use a technique called [\"one-hot encoding\"](https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b) using a helper method from Keras. Now each class will be represented by an array of mostly 0s. By the way, we'll use these same arrays when we start classifying data with our model, only then the values aren't going to be crisp 0s and 1s, but somewhere in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partnum</th>\n",
       "      <th>class</th>\n",
       "      <th>dataset</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>MPMT-10K/10KDKR-ND</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[32, 23, 32, 37, 9, 50, 24, 8, 15, 50, 24, 8, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>556-ATMEGA328PB-MNR</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[10, 10, 29, 9, 7, 37, 32, 13, 2, 7, 3, 22, 12...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>652-CRA2512FZR100ELF</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[29, 10, 22, 9, 16, 38, 7, 22, 10, 50, 22, 18,...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>296-35502-1-ND</td>\n",
       "      <td>2</td>\n",
       "      <td>val</td>\n",
       "      <td>[22, 46, 29, 9, 3, 10, 10, 24, 22, 9, 50, 9, 1...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>649-67997-106HLF</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>[29, 25, 46, 9, 29, 26, 46, 46, 26, 9, 50, 24,...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    partnum  class dataset  \\\n",
       "7218     MPMT-10K/10KDKR-ND      2   train   \n",
       "18646   556-ATMEGA328PB-MNR      1   train   \n",
       "4440   652-CRA2512FZR100ELF      1   train   \n",
       "3437         296-35502-1-ND      2     val   \n",
       "24360      649-67997-106HLF      1     val   \n",
       "\n",
       "                                                       x                y  \n",
       "7218   [32, 23, 32, 37, 9, 50, 24, 8, 15, 50, 24, 8, ...  [0.0, 0.0, 1.0]  \n",
       "18646  [10, 10, 29, 9, 7, 37, 32, 13, 2, 7, 3, 22, 12...  [0.0, 1.0, 0.0]  \n",
       "4440   [29, 10, 22, 9, 16, 38, 7, 22, 10, 50, 22, 18,...  [0.0, 1.0, 0.0]  \n",
       "3437   [22, 46, 29, 9, 3, 10, 10, 24, 22, 9, 50, 9, 1...  [0.0, 0.0, 1.0]  \n",
       "24360  [29, 25, 46, 9, 29, 26, 46, 46, 26, 9, 50, 24,...  [0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = list(list(l) for l in to_categorical(df['class']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model\n",
    "\n",
    "We are now ready to build and train the model. The simple architecture of this particular network was taken from a [Keras example](https://github.com/keras-team/keras/blob/2.0.5/examples/imdb_lstm.py), and it just happened to work for our toy problem with only minor modifications, so we'll just leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d(col, ds, class_filter=None):\n",
    "    if class_filter is not None:\n",
    "        return list(df[(df['dataset'] == ds) & (df['class'] == class_filter)][col])\n",
    "    else:\n",
    "        return list(df[df['dataset'] == ds][col])            \n",
    "\n",
    "# config\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 11344 samples, validate on 2789 samples\n",
      "Epoch 1/7\n",
      "11344/11344 [==============================] - 14s - loss: 0.6081 - acc: 0.6560 - val_loss: 0.3809 - val_acc: 0.8200\n",
      "Epoch 2/7\n",
      "11344/11344 [==============================] - 12s - loss: 0.2809 - acc: 0.8876 - val_loss: 0.1270 - val_acc: 0.9577\n",
      "Epoch 3/7\n",
      "11344/11344 [==============================] - 12s - loss: 0.1482 - acc: 0.9517 - val_loss: 0.0805 - val_acc: 0.9745\n",
      "Epoch 4/7\n",
      "11344/11344 [==============================] - 12s - loss: 0.1033 - acc: 0.9679 - val_loss: 0.0655 - val_acc: 0.9806\n",
      "Epoch 5/7\n",
      "11344/11344 [==============================] - 12s - loss: 0.0841 - acc: 0.9715 - val_loss: 0.0580 - val_acc: 0.9796\n",
      "Epoch 6/7\n",
      "11344/11344 [==============================] - 12s - loss: 0.0698 - acc: 0.9772 - val_loss: 0.0476 - val_acc: 0.9857\n",
      "Epoch 7/7\n",
      "11344/11344 [==============================] - 12s - loss: 0.0646 - acc: 0.9790 - val_loss: 0.0420 - val_acc: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f919393df98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(partnum_dict)+1, 32))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(d('x', 'train'), d('y', 'train'),\n",
    "          batch_size=batch_size,\n",
    "          epochs=7,\n",
    "          validation_data=(d('x', 'val'), d('y', 'val')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789/2789 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Accuracy of the model: 98.49%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, acc = model.evaluate(d('x', 'val'), d('y', 'val'), batch_size=batch_size)\n",
    "display(Markdown('### Accuracy of the model: {:.2f}%'.format(acc * 100.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, but I'm actually curious as to what kind of samples were miscategorized.\n",
    "\n",
    "## Save the model to disk\n",
    "\n",
    "Let's try predicting samples from each class separately to get an idea of where the model gets confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/921 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPN</td>\n",
       "      <td>96.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mouser SKU</td>\n",
       "      <td>99.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Digi-Key SKU</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class accuracy\n",
       "0           MPN   96.19%\n",
       "1    Mouser SKU   99.26%\n",
       "2  Digi-Key SKU  100.00%"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for c in sorted(df['class'].unique()):\n",
    "    score, acc = model.evaluate(d('x', 'val', class_filter=c), d('y', 'val', class_filter=c), batch_size=batch_size)\n",
    "    res.append([class_names[c], '{:.2f}%'.format(acc*100.0)])\n",
    "pd.DataFrame(res, columns=['class', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the model nailed the Digi-Key SKUs, is very good with Mouser SKUs, but is misclassifying some part numbers as either Mouser or Digi-Key SKUs. Let's save the model so that we can reload it in [part 2](parts-distributor-sku-classifier-part-2-explore.ipynb) of the notebook and poke around a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Serialize the model architecture\n",
    "with open(\"data/trained_model_layers.json\", \"w\") as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "\n",
    "# Serialize the model weights to HDF5\n",
    "model.save_weights(\"data/trained_model_weights.h5\")\n",
    "\n",
    "# Serialize our part number character dictionary - we'll need it to classify strings\n",
    "with open(\"data/char_dictionary.json\", \"w\") as json_file:\n",
    "    json.dump(partnum_dict, json_file)\n",
    "    \n",
    "# Finally, save our cleaned and prepared data set - we'll need it to explore the model in part 2\n",
    "df.to_json(\"data/cleaned_training_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up next\n",
    "\n",
    "In [part 2](parts-distributor-sku-classifier-part-2-explore.ipynb) of this notebook, we'll analyze the model performance and try to get a feel for how LSTM neural network works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
